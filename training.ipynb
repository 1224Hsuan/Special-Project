{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0ow6zQnICuov",
        "zcQ3GkDiDBHo"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 連接雲端與切換資料夾"
      ],
      "metadata": {
        "id": "0ow6zQnICuov"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYnprHzBCLG6",
        "outputId": "a7f85212-d4a9-4a9f-fdf3-986e7f25f091"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/專題實驗/training_3-15/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dt0Q1uBrCiM8",
        "outputId": "330241bc-f9d3-483e-d53a-17fe828ea451"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/專題實驗/training_3-15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 訓練與測試"
      ],
      "metadata": {
        "id": "zcQ3GkDiDBHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "\n",
        "imgSize = (224, 224)\n",
        "batchSize = 32\n",
        "\n",
        "# set the training dataset\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"train\",\n",
        "    validation_split = 0.1,\n",
        "    subset = \"training\",\n",
        "    seed = 1337,\n",
        "    image_size = imgSize,\n",
        "    batch_size = batchSize,\n",
        ")\n",
        "\n",
        "# set the validation dataset\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"validation\",\n",
        "    validation_split = 0.9,\n",
        "    subset = \"validation\",\n",
        "    seed = 1337,\n",
        "    image_size = imgSize,\n",
        "    batch_size = batchSize,\n",
        ")\n",
        "\n",
        "# set the data augmentation\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.Rescaling(0.7),\n",
        "        layers.Rescaling(0.8),\n",
        "        layers.RandomTranslation((-0.2, 0.3), (-0.2, 0.3)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# set the training model\n",
        "def setModel(inputSize, typeNum):\n",
        "    input = keras.Input(shape = inputSize)\n",
        "    x = data_augmentation(input)\n",
        "    x = layers.Rescaling(1.0 / 255)(x)\n",
        "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    previous_block_activation = x\n",
        "\n",
        "    for size in [128, 256, 512, 728]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = layers.add([x, residual])\n",
        "        previous_block_activation = x\n",
        "\n",
        "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    activation = \"sigmoid\"\n",
        "    units = 1\n",
        "\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    output = layers.Dense(units, activation=activation)(x)\n",
        "    return keras.Model(input, output)\n",
        "\n",
        "\n",
        "model = setModel(imgSize + (3,), 2)\n",
        "keras.utils.plot_model(model, show_shapes=True)\n",
        "\n",
        "epochs = 50\n",
        "callbacks = [keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),]\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-3),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    train_ds,\n",
        "    epochs = epochs,\n",
        "    callbacks = callbacks,\n",
        "    validation_data = val_ds,\n",
        ")\n",
        "\n",
        "# save the final model and weights\n",
        "model.save('model.hdf5')\n",
        "model.save_weights('model_weights.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSwspy7HCojI",
        "outputId": "0b83062a-c38c-4772-dac4-f26dd978134f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2712 files belonging to 2 classes.\n",
            "Using 2441 files for training.\n",
            "Found 793 files belonging to 2 classes.\n",
            "Using 713 files for validation.\n",
            "Epoch 1/50\n",
            "77/77 [==============================] - 868s 11s/step - loss: 0.5325 - accuracy: 0.7460 - val_loss: 0.7096 - val_accuracy: 0.5091\n",
            "Epoch 2/50\n",
            "77/77 [==============================] - 32s 407ms/step - loss: 0.3958 - accuracy: 0.8197 - val_loss: 0.7939 - val_accuracy: 0.5091\n",
            "Epoch 3/50\n",
            "77/77 [==============================] - 32s 407ms/step - loss: 0.3601 - accuracy: 0.8443 - val_loss: 1.0059 - val_accuracy: 0.5091\n",
            "Epoch 4/50\n",
            "77/77 [==============================] - 32s 406ms/step - loss: 0.3198 - accuracy: 0.8636 - val_loss: 0.9739 - val_accuracy: 0.5091\n",
            "Epoch 5/50\n",
            "77/77 [==============================] - 32s 405ms/step - loss: 0.2988 - accuracy: 0.8730 - val_loss: 0.9320 - val_accuracy: 0.5091\n",
            "Epoch 6/50\n",
            "77/77 [==============================] - 32s 405ms/step - loss: 0.2744 - accuracy: 0.8816 - val_loss: 0.6599 - val_accuracy: 0.5568\n",
            "Epoch 7/50\n",
            "77/77 [==============================] - 32s 405ms/step - loss: 0.2441 - accuracy: 0.8980 - val_loss: 0.3392 - val_accuracy: 0.8724\n",
            "Epoch 8/50\n",
            "77/77 [==============================] - 32s 407ms/step - loss: 0.2552 - accuracy: 0.8865 - val_loss: 0.1692 - val_accuracy: 0.9439\n",
            "Epoch 9/50\n",
            "77/77 [==============================] - 32s 404ms/step - loss: 0.2422 - accuracy: 0.8955 - val_loss: 0.1978 - val_accuracy: 0.9313\n",
            "Epoch 10/50\n",
            "77/77 [==============================] - 32s 405ms/step - loss: 0.2207 - accuracy: 0.9082 - val_loss: 1.9805 - val_accuracy: 0.5091\n",
            "Epoch 11/50\n",
            "77/77 [==============================] - 32s 406ms/step - loss: 0.2262 - accuracy: 0.9050 - val_loss: 0.3350 - val_accuracy: 0.8583\n",
            "Epoch 12/50\n",
            "77/77 [==============================] - 32s 406ms/step - loss: 0.2019 - accuracy: 0.9132 - val_loss: 0.2449 - val_accuracy: 0.8892\n",
            "Epoch 13/50\n",
            "77/77 [==============================] - 32s 410ms/step - loss: 0.1972 - accuracy: 0.9181 - val_loss: 0.1084 - val_accuracy: 0.9523\n",
            "Epoch 14/50\n",
            "77/77 [==============================] - 32s 407ms/step - loss: 0.1847 - accuracy: 0.9234 - val_loss: 0.3188 - val_accuracy: 0.8612\n",
            "Epoch 15/50\n",
            "77/77 [==============================] - 32s 406ms/step - loss: 0.1969 - accuracy: 0.9185 - val_loss: 0.2667 - val_accuracy: 0.8738\n",
            "Epoch 16/50\n",
            "77/77 [==============================] - 32s 407ms/step - loss: 0.1767 - accuracy: 0.9267 - val_loss: 0.3313 - val_accuracy: 0.8373\n",
            "Epoch 17/50\n",
            "77/77 [==============================] - 32s 405ms/step - loss: 0.1727 - accuracy: 0.9304 - val_loss: 1.8911 - val_accuracy: 0.5512\n",
            "Epoch 18/50\n",
            "77/77 [==============================] - 32s 408ms/step - loss: 0.1758 - accuracy: 0.9267 - val_loss: 0.3339 - val_accuracy: 0.8569\n",
            "Epoch 19/50\n",
            "77/77 [==============================] - 32s 405ms/step - loss: 0.1596 - accuracy: 0.9369 - val_loss: 1.3185 - val_accuracy: 0.5358\n",
            "Epoch 20/50\n",
            "77/77 [==============================] - 32s 407ms/step - loss: 0.1596 - accuracy: 0.9349 - val_loss: 0.1993 - val_accuracy: 0.9243\n",
            "Epoch 21/50\n",
            "77/77 [==============================] - 32s 405ms/step - loss: 0.1728 - accuracy: 0.9254 - val_loss: 0.1441 - val_accuracy: 0.9285\n",
            "Epoch 22/50\n",
            "77/77 [==============================] - 32s 404ms/step - loss: 0.1571 - accuracy: 0.9385 - val_loss: 0.7230 - val_accuracy: 0.7111\n",
            "Epoch 23/50\n",
            "77/77 [==============================] - 32s 408ms/step - loss: 0.1584 - accuracy: 0.9402 - val_loss: 0.7613 - val_accuracy: 0.7560\n",
            "Epoch 24/50\n",
            "77/77 [==============================] - 32s 406ms/step - loss: 0.1429 - accuracy: 0.9402 - val_loss: 0.3285 - val_accuracy: 0.8527\n",
            "Epoch 25/50\n",
            "77/77 [==============================] - 32s 406ms/step - loss: 0.1348 - accuracy: 0.9492 - val_loss: 0.2974 - val_accuracy: 0.8429\n",
            "Epoch 26/50\n",
            "77/77 [==============================] - 32s 407ms/step - loss: 0.1340 - accuracy: 0.9484 - val_loss: 0.3171 - val_accuracy: 0.8471\n",
            "Epoch 27/50\n",
            "77/77 [==============================] - 32s 406ms/step - loss: 0.1268 - accuracy: 0.9467 - val_loss: 0.9509 - val_accuracy: 0.6353\n",
            "Epoch 28/50\n",
            "77/77 [==============================] - 32s 409ms/step - loss: 0.1381 - accuracy: 0.9431 - val_loss: 0.0997 - val_accuracy: 0.9593\n",
            "Epoch 29/50\n",
            "77/77 [==============================] - 32s 406ms/step - loss: 0.1350 - accuracy: 0.9455 - val_loss: 0.0869 - val_accuracy: 0.9621\n",
            "Epoch 30/50\n",
            "77/77 [==============================] - 32s 406ms/step - loss: 0.1409 - accuracy: 0.9472 - val_loss: 0.1942 - val_accuracy: 0.9215\n",
            "Epoch 31/50\n",
            "77/77 [==============================] - 32s 408ms/step - loss: 0.1174 - accuracy: 0.9537 - val_loss: 0.3174 - val_accuracy: 0.8738\n",
            "Epoch 32/50\n",
            "77/77 [==============================] - 32s 406ms/step - loss: 0.1233 - accuracy: 0.9504 - val_loss: 1.5118 - val_accuracy: 0.5835\n",
            "Epoch 33/50\n",
            "77/77 [==============================] - 32s 407ms/step - loss: 0.1176 - accuracy: 0.9537 - val_loss: 0.3033 - val_accuracy: 0.8555\n",
            "Epoch 34/50\n",
            "77/77 [==============================] - 32s 405ms/step - loss: 0.1134 - accuracy: 0.9521 - val_loss: 0.8068 - val_accuracy: 0.7714\n",
            "Epoch 35/50\n",
            "77/77 [==============================] - 32s 406ms/step - loss: 0.1161 - accuracy: 0.9533 - val_loss: 0.3225 - val_accuracy: 0.8682\n",
            "Epoch 36/50\n",
            "77/77 [==============================] - 32s 407ms/step - loss: 0.1284 - accuracy: 0.9459 - val_loss: 0.2192 - val_accuracy: 0.9088\n",
            "Epoch 37/50\n",
            "77/77 [==============================] - 32s 408ms/step - loss: 0.1117 - accuracy: 0.9586 - val_loss: 0.2495 - val_accuracy: 0.8850\n",
            "Epoch 38/50\n",
            "77/77 [==============================] - 32s 407ms/step - loss: 0.1136 - accuracy: 0.9562 - val_loss: 0.1139 - val_accuracy: 0.9495\n",
            "Epoch 39/50\n",
            "77/77 [==============================] - 32s 407ms/step - loss: 0.1174 - accuracy: 0.9533 - val_loss: 0.2467 - val_accuracy: 0.8962\n",
            "Epoch 40/50\n",
            "77/77 [==============================] - 32s 405ms/step - loss: 0.1329 - accuracy: 0.9463 - val_loss: 0.4603 - val_accuracy: 0.8640\n",
            "Epoch 41/50\n",
            "77/77 [==============================] - 32s 406ms/step - loss: 0.1014 - accuracy: 0.9582 - val_loss: 0.0808 - val_accuracy: 0.9719\n",
            "Epoch 42/50\n",
            "77/77 [==============================] - 32s 408ms/step - loss: 0.1126 - accuracy: 0.9562 - val_loss: 0.1621 - val_accuracy: 0.9411\n",
            "Epoch 43/50\n",
            "77/77 [==============================] - 32s 405ms/step - loss: 0.1188 - accuracy: 0.9541 - val_loss: 0.0798 - val_accuracy: 0.9705\n",
            "Epoch 44/50\n",
            "77/77 [==============================] - 32s 406ms/step - loss: 0.1138 - accuracy: 0.9541 - val_loss: 1.2645 - val_accuracy: 0.7279\n",
            "Epoch 45/50\n",
            "77/77 [==============================] - 32s 408ms/step - loss: 0.0939 - accuracy: 0.9623 - val_loss: 0.1961 - val_accuracy: 0.9369\n",
            "Epoch 46/50\n",
            "77/77 [==============================] - 32s 410ms/step - loss: 0.1040 - accuracy: 0.9599 - val_loss: 1.4108 - val_accuracy: 0.5961\n",
            "Epoch 47/50\n",
            "77/77 [==============================] - 32s 405ms/step - loss: 0.1050 - accuracy: 0.9586 - val_loss: 0.3397 - val_accuracy: 0.8724\n",
            "Epoch 48/50\n",
            "77/77 [==============================] - 32s 407ms/step - loss: 0.0985 - accuracy: 0.9635 - val_loss: 0.1942 - val_accuracy: 0.9116\n",
            "Epoch 49/50\n",
            "77/77 [==============================] - 32s 405ms/step - loss: 0.1046 - accuracy: 0.9607 - val_loss: 0.0900 - val_accuracy: 0.9734\n",
            "Epoch 50/50\n",
            "77/77 [==============================] - 32s 406ms/step - loss: 0.1136 - accuracy: 0.9545 - val_loss: 0.0506 - val_accuracy: 0.9804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 預測"
      ],
      "metadata": {
        "id": "QsP-17-YYSnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/執行結果/3-17執行結果_2/\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import load_img\n",
        "\n",
        "# load the model\n",
        "model = load_model('model.hdf5')\n",
        "\n",
        "# load the image\n",
        "%cd /content/drive/MyDrive/專題實驗/test/\n",
        "img = keras.preprocessing.image.load_img(\n",
        "    \"110.jpg\", target_size = (224, 224)\n",
        ")\n",
        "img_array = keras.preprocessing.image.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)\n",
        "\n",
        "# predict and get the result\n",
        "predictions = model.predict(img_array)\n",
        "score = predictions[0]\n",
        "print(\n",
        "    \"This image is %.2f percent rainy and %.2f percent sunny.\"\n",
        "    % (100 * (1 - score), 100 * score)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFsL70WHYWvg",
        "outputId": "048f92f2-2954-44d7-dd2c-aaa05c578462"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/執行結果/3-17執行結果_2\n",
            "/content/drive/MyDrive/專題實驗/test\n",
            "This image is 2.43 percent rainy and 97.57 percent sunny.\n"
          ]
        }
      ]
    }
  ]
}